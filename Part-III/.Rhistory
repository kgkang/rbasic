result
choice2 <- sample(c(10:50, 70:150, 160:190),30)
choice2
idx <- sample(1:nrow(iris),0.7*nrow(iris))
idx
train <- iris[idx,]
test <- iris[-idx,]
dim(train)
dim(test)
install.packages("mlmRev")
library(mlmRev)
data(Chem97) # Chem97 데이터 셋 로드
str(Chem97) # 차원보기
head(Chem97,30)
range(Chem97$score)
table(Chem97$score)
histogram(~gcsescore, data=Chem97)
histogram(~gcsescore | score, data=Chem97)
histogram(~gcsescore | factor(score), data=Chem97)
histogram(~gcsescore | score, data=Chem97)
histogram(~gcsescore | factor(score), data=Chem97)
densityplot(~gcsescore | factor(score), data=Chem97,
groups = gender, plot.points=T, auto.key = T)
data(VADeaths)
VADeaths
str(VADeaths)
mode(VADeaths) # numeric
class(VADeaths) # matrix
df <- as.data.frame(VADeaths)
str(df)
class(df)
df
dft <- as.data.frame.table(VADeaths)
str(dft)
class(dft)
dft
barchart(Var1 ~ Freq | Var2, data=dft, layout=c(4,1))
dotplot(Var1 ~ Freq | Var2 , dft)
dotplot(Var1 ~ Freq, data=dft, groups=Var2, type="o",
auto.key=list(space="right", points=T, lines=T))
library(datasets)
str(airquality) # airqulity 테이터 셋 로드
table(airquality$Month)
xyplot(Ozone ~ Wind, data=airquality)
xyplot(Ozone ~ Wind | Month, data=airquality)
xyplot(Ozone ~ Wind | Month, data=airquality, layout=c(5,1))
head(quakes) # quakes 데이터셋 로드
str(quakes)
xyplot(lat~long, data=quakes, pch=".")
tplot<-xyplot(lat~long, data=quakes, pch=".")
tplot2<-update(tplot,
main="1964년 이후 태평양에서 발생한 지진위치")
print(tplot2)
depthgroup<-equal.count(quakes$depth, number=3, overlap=0)
equal(1:150, 3, overlap=0)
equal.count(1:150, 3, overlap=0)
depthgroup<-equal.count(quakes$depth, number=3, overlap=0)
depthgroup
depthgroup
str(depthgroup)
head(depthgroup,10)
depthgroup<-equal.count(quakes$depth, number=3, overlap=0)
depthgroup
xyplot(lat ~ long | depthgroup, data=quakes,
main="Fiji Earthquakes(depthgruop)",
ylab="latitude", xlab="longitude", pch="@", col='red' )
cloud(depth ~ lat * long , data=quakes,
zlim=rev(range(quakes$depth)),
xlab="경도", ylab="위도", zlab="깊이")
install.packages("ggplot2") # 패키지 설치
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
data(diamonds) # 데이터 셋 가져오기
data(mtcars)
data(mpg)
str(mpg) # map 데이터 셋 구조 보기
head(mpg) # map 데이터 셋 내용 보기
summary(mpg) # 요약 통계량
table(mpg$drv) # 구동방식 빈도수
qplot(hwy, data=mpg) # 세로막대 그래프
qplot(hwy, data=mpg, fill=drv) # fill 옵션 적용
qplot(hwy, data=mpg, fill=drv, binwidth=2) # binwidth 옵션 적용
qplot(hwy, data=mpg, fill=drv, facets=.~ drv, binwidth=2) # 열 단위 패널 생성
qplot(hwy, data=mpg, fill=drv, facets=drv~., binwidth=2) # 행 단위 패널 생성
qplot(displ, hwy, data=mpg)# mpg 데이터셋의 displ과 hwy변수 이용
qplot(displ, hwy, data=mpg, color=drv)
head(mtcars)
str(mtcars) # ggplot2에서 제공하는 데이터 셋
qplot(wt, mpg, data=mtcars, color=factor(carb)) # 색상 적용
qplot(wt, mpg, data=mtcars, size=qsec, color=factor(carb)) # 크기 적용
qplot(wt, mpg, data=mtcars, size=qsec, color=factor(carb), shape=factor(cyl))#모양 적용
mtcars$qsec
head(diamonds)
qplot(clarity, data=diamonds, fill=cut, geom="bar") # 레이아웃에 색 채우기
qplot(clarity, data=diamonds, colour=cut, geom="bar") # 테두리 색 적용
qplot(wt, mpg, data=mtcars, size=qsec) # geom="point" 기본
qplot(wt, mpg, data=mtcars, size=qsec, geom="point")
qplot(wt, mpg, data=mtcars, size=factor(cyl), color=factor(carb), geom="point")
qplot(wt, mpg, data=mtcars, size=qsec, color=factor(carb), shape=factor(cyl), geom="point")
qplot(wt, mpg, data=mtcars, geom=c("point", "smooth"))
qplot(wt, mpg, data=mtcars, color=factor(cyl), geom=c("point", "smooth"))
qplot(mpg, wt, data=mtcars, color=factor(cyl), geom="line")
qplot(mpg, wt, data=mtcars, color=factor(cyl), geom="point") + geom_line()
qplot(clarity, data=diamonds, geom="freqpoly", group=cut, colour=cut)
qplot(clarity, data=diamonds, geom="bar", fill=cut, position="identity")
qplot(clarity, data=diamonds, geom="bar", fill=cut, position="fill")
qplot(clarity, data=diamonds, geom="bar", fill=cut, position="stack")
qplot(clarity, data=diamonds, geom="bar", fill=cut, position="dodge")
p <-ggplot(diamonds, aes(carat, price, color=cut))
p + geom_point() # point 추가
p<- ggplot(mtcars, aes(mpg,wt,color=factor(cyl)))
p+geom_line() # line 추가
p<- ggplot(mtcars, aes(mpg,wt,color=factor(cyl)))
p+geom_point()  # point 추가
p<- ggplot(mtcars, aes(mpg,wt,color=factor(cyl)))
p+geom_step()  # step 추가
p<- ggplot(diamonds, aes(clarity))
p+geom_bar(aes(fill=cut), position="fill")  # bar 추가
p<-ggplot(diamonds, aes(carat, price, color=cut))
p+geom_point()  # point 추가
ggsave(file="C:/Rwork/output/diamond_price.pdf") # 가장 최근 그래프 저장
ggsave(file="C:/Rwork/output/diamond_price.jpg", dpi=72)
pop <- read.csv("C:/Rwork/Part-II/population201506.csv",header=T)
pop
region <- pop$지역명
lon <- pop$LON # 위도
lat <- pop$LAT # 경도
house <- pop$세대수
# 위도,경도,세대수 이용 데이터프레임 생성
df <- data.frame(region, lon,lat,house)
df
map1 <- get_map("daegu", zoom=7 ,  maptype='watercolor')
library(ggplot2)
install.packages("ggmap") # ‘ggmap’와 ‘ggplot2’(우선 설치) 관련 패키지
library(ggmap)
gc<- geocode("seoul, korea", source="google") # geolocation API 이용
gc
center <- as.numeric(gc) #수치로 변환
center # 위도,경도
map <- get_googlemap(center = center, language="ko-KR", color = "bw", scale = 2 )
ggmap(map, extent = 'device')
map <- get_map(location ="london", zoom=14, maptype='roadmap', scale=2)
ggmap(map, size=c(600,600), extent='device')
map <- get_map(location ="seoul", zoom=14, maptype='watercolor', scale=2)
ggmap(map, size=c(600,600), extent='device')
map <- get_map(location ="seoul", zoom=14, scale=2)
map <- get_map(location ="seoul", zoom=8, scale=2)
ggmap(map, size=c(600,600), extent='device')
map <- get_map(location ="seoul", zoom=14, scale=2)
ggmap(map, size=c(600,600), extent='device')
university <- read.csv("C:/Rwork/Part-II/university.csv",header=T)
university # # 학교명","LAT","LON"
kor <- get_map("seoul", zoom=11, maptype = "watercolor")#roadmap
ggmap(kor)+geom_point(data=university, aes(x=LON, y=LAT,color=factor(학교명)),size=3)
kor.map <- ggmap(kor)+geom_point(data=university, aes(x=LON, y=LAT,color=factor(학교명)),size=3)
kor.map + geom_text(data=university, aes(x=LON+0.01, y=LAT+0.01,label=학교명),size=5)
pop <- read.csv("C:/Rwork/Part-II/population201506.csv",header=T)
pop
region <- pop$지역명
lon <- pop$LON # 위도
lat <- pop$LAT # 경도
house <- pop$세대수
# 위도,경도,세대수 이용 데이터프레임 생성
df <- data.frame(region, lon,lat,house)
df
map1 <- get_map("daegu", zoom=7 ,  maptype='watercolor')
map2 <- ggmap(map1)
map2
map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 <- map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01, y=lat+0.18,label=region),size=3)
ggsave("C:/Rwork/output/population201506.png",scale=1,width=10.24,height=7.68)
map1 <- get_map("daegu", zoom=7 ,  maptype='terrain')
map2 <- ggmap(map1)
map3 <- map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01, y=lat+0.18,label=region),size=3)
map1 <- get_map("daegu", zoom=7 ,  maptype='satellite')
map2 <- ggmap(map1)
map3 <- map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01,y=lat+0.18,colour=region,label=region),size=3)
map1 <- get_map("daegu", zoom=7 ,  maptype='roadmap')
map2 <- ggmap(map1)
map3 <- map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01, y=lat+0.18,label=region),size=3)
map1 <- get_map("jeonju", zoom=7,  maptype='hybrid')
map2 <- ggmap(map1)
map3 <- map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01, y=lat+0.18,label=region),size=3)
map3 + geom_density2d()
ㅇㄹ
df
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Rutil\\Java\\jre1.8.0_111')
library(rJava) # 로딩
install.packages(c("KoNLP", "tm", "wordcloud"))
library(KoNLP)
library(tm)
library(wordcloud)
facebook <- file("C:/Rwork/Part-II/facebook_bigdata.txt", encoding="UTF-8")
facebook_data <- readLines(facebook) # 줄 단위 데이터 생성
head(facebook_data) # 앞부분 6줄 보기 - 줄 단위 문장 확인
str(facebook_data) # chr [1:76]
facebook_corpus <- Corpus(VectorSource(facebook_data))
facebook_corpus <- Corpus(VectorSource(facebook_data))
facebook_corpus
inspect(facebook_corpus)
facebook_corpus[is.na(facebook_corpus)]   <- " "
facebook_corpus
useSejongDic() # 세종 사전 불러오기
mergeUserDic(data.frame(c("R 프로그래밍","페이스북","소셜네트워크"), c("ncn")))
extractNoun("나는 홍길동입니다, 우리나라 만세!!")
extractNoun("나는 홍길동 입니다, 우리나라 만세!!")
exNouns <- function(x) {
paste(extractNoun(as.character(x)), collapse=" ")
}
facebook_nouns <- sapply(facebook_corpus, exNouns)
facebook_nouns[1] # 단어만 추출된 첫 줄 보기
myCorputfacebook <- Corpus(VectorSource(facebook_nouns))
myCorputfacebook <- tm_map(myCorputfacebook, removePunctuation) # 문장부호 제거
myCorputfacebook <- tm_map(myCorputfacebook, removeNumbers) # 수치 제거
myCorputfacebook <- tm_map(myCorputfacebook, tolower) # 소문자 변경
myCorputfacebook <-tm_map(myCorputfacebook, removeWords, stopwords('english')) # 불용어제거
inspect(myCorputfacebook[1:5]) # 데이터 전처리 결과 확인
myCorputfacebook_txt <- tm_map(myCorputfacebook, PlainTextDocument)
myCorputfacebook_txt <- TermDocumentMatrix(myCorputfacebook_txt, control=list(wordLengths=c(2,Inf)))
myCorputfacebook_txt
myTermfacebook.df <- as.data.frame(as.matrix(myCorputfacebook_txt))
dim(myTermfacebook.df) # [1] 876  76
wordResult <- sort(rowSums(myTermfacebook.df), decreasing=TRUE) # 빈도수로 내림차순 정렬
wordResult[1:10]
myCorputfacebook <- tm_map(myCorputfacebook, removePunctuation) # 문장부호 제거
myCorputfacebook <- tm_map(myCorputfacebook, removeNumbers) # 수치 제거
myCorputfacebook <- tm_map(myCorputfacebook, tolower) # 소문자 변경
myStopwords = c(stopwords('english'), "사용", "하기");
myCorputfacebook = tm_map(myCorputfacebook, removeWords, myStopwords);
myCorputfacebook_txt <- tm_map(myCorputfacebook, PlainTextDocument)
myCorputfacebook_txt <- TermDocumentMatrix(myCorputfacebook_txt, control=list(wordLengths=c(2,Inf)))
myTermfacebook.df <- as.data.frame(as.matrix(myCorputfacebook_txt))
dim(myTermfacebook.df) # [1] 876  76
wordResult <- sort(rowSums(myTermfacebook.df), decreasing=TRUE) # 빈도수로 내림차순 정렬
wordResult[1:10]
myName <- names(wordResult) # 단어 이름 추출(빈도수 이름)
wordcloud(myName, wordResult) # 단어구름 시각화
word.df <- data.frame(word=myName, freq=wordResult)
str(word.df) # word, freq 변수
pal <- brewer.pal(12,"Paired") # 12가지 색상 pal <- brewer.pal(9,"Set1") # Set1~ Set3
windowsFonts(malgun=windowsFont("맑은 고딕"))  #windows
x11( ) # 별도의 창을 띄우는 함수
pal <- brewer.pal(12,"Paired") # 12가지 색상 pal <- brewer.pal(9,"Set1") # Set1~ Set3
windowsFonts(malgun=windowsFont("맑은 고딕"))  #windows
x11( ) # 별도의 창을 띄우는 함수
source('C:/Rwork/chap10_Informal.R', encoding = 'UTF-8', echo=TRUE)
install.packages("rJava")
wordcloud(word.df$word, word.df$freq,
scale=c(5,1), min.freq=3, random.order=F,
rot.per=.1, colors=pal, family="malgun")
myName <- names(wordResult) # 단어 이름 추출(빈도수 이름)
wordcloud(myName, wordResult) # 단어구름 시각화
word.df <- data.frame(word=myName, freq=wordResult)
str(word.df) # word, freq 변수
pal <- brewer.pal(12,"Paired") # 12가지 색상 pal <- brewer.pal(9,"Set1") # Set1~ Set3
windowsFonts(malgun=windowsFont("맑은 고딕"))  #windows
x11( ) # 별도의 창을 띄우는 함수
wordcloud(word.df$word, word.df$freq,
scale=c(5,1), min.freq=3, random.order=F,
rot.per=.1, colors=pal, family="malgun")
11. 차트 시각화
#(1) 상위 10개 토픽추출
topWord <- head(sort(wordResult, decreasing=T), 10) # 상위 10개 토픽추출
# (2) 파일 차트 생성
pie(topWord, col=rainbow(10), radius=1) # 파이 차트-무지개색, 원크기
# (3) 빈도수 백분율 적용
pct <- round(topWord/sum(topWord)*100, 1) # 백분율
names(topWord)
# (4) 단어와 백분율 하나로 합친다.
lab <- paste(names(topWord), "\n", pct, "%")
# (5) 파이차트에 단어와 백분율을 레이블로 적용
pie(topWord, main="SNS 빅데이터 관련 토픽분석", col=rainbow(10), cex=0.8, labels=lab)
marketing <- file("C:/Rwork/Part-II/marketing.txt", encoding="UTF-8")
marketing2 <- readLines(marketing) # 줄 단위 데이터 생성
close(marketing)
head(marketing2) # 앞부분 6줄 보기 - 줄 단위 문장 확인
lword <- Map(extractNoun, marketing2)
length(lword) # [1] 472
marketing <- file("C:/Rwork/Part-II/marketing.txt", encoding="UTF-8")
marketing2 <- readLines(marketing) # 줄 단위 데이터 생성
lword <- Map(extractNoun, marketing2)
Sys.setenv(JAVA_HOME='C:\\Rutil\\Java\\jre1.8.0_111')
library(rJava) # 아래와 같은 Error 발생 시 Sys.setenv()함수로 java 경로 지정
install.packages("KoNLP")
library(KoNLP) # rJava 라이브러리가 필요함
marketing <- file("C:/Rwork/Part-II/marketing.txt", encoding="UTF-8")
marketing2 <- readLines(marketing) # 줄 단위 데이터 생성
close(marketing)
head(marketing2) # 앞부분 6줄 보기 - 줄 단위 문장 확인
lword <- Map(extractNoun, marketing2)
length(lword) # [1] 472
lword <- unique(lword) # 중복제거1(전체 대상)
length(lword) # [1] 353(19개 제거)
lword <- sapply(lword, unique) # 중복제거2(줄 단위 대상)
length(lword) # [1] 352(1개 제거)
str(lword) # List of 353
lword # 추출 단어 확인
filter1 <- function(x){
nchar(x) <= 4 && nchar(x) >= 2 && is.hangul(x)
}
filter2 <- function(x){
Filter(filter1, x)
}
lword <- sapply(lword, filter2)
lword # 추출 단어 확인(길이 1개 단어 삭제됨)
install.packages("arules")
library(arules)
filter2 <- function(x){
Filter(filter1, x)
}
lword <- sapply(lword, filter2)
lword # 추출 단어 확인(길이 1개 단어 삭제됨)
install.packages("arules")
install.packages("arules")
library(arules)
wordtran <- as(lword, "transactions") # lword에 중복데이터가 있으면 error발생
wordtran
wordtable <- crossTable(wordtran) # 교차표 작성
wordtable
tranrules <- apriori(wordtran, parameter=list(supp=0.25, conf=0.05))
inspect(tranrules) # 연관규칙 생성 결과(59개) 보기
rules <- labels(tranrules, ruleSep=" ")
class(rules)
rules <- sapply(rules, strsplit, " ",  USE.NAMES=F)
rulemat <- do.call("rbind", rules)
rulemat
class(rulemat)
install.packages("igraph") # graph.edgelist(), plot.igraph(), closeness() 함수 제공
library(igraph)
ruleg <- graph.edgelist(rulemat[c(12:59),], directed=F) # [1,]~[11,] "{}" 제외
ruleg
plot.igraph(ruleg, vertex.label=V(ruleg)$name,
vertex.label.cex=1.2, vertex.label.color='black',
vertex.size=20, vertex.color='green', vertex.frame.color='blue')
closen <- closeness(ruleg) # edgelist 대상 단어 근접중심성 생성
closen <- closen[c(1:10)] # 상위 1~10 단어 근접중심성 보기
plot(closen, col="red",xaxt="n", lty="solid", type="b", xlab="단어", ylab="closeness")
points(closen, pch=16, col="navy")
axis(1, seq(1, length(closen)), V(ruleg)$name[c(1:10)], cex=5)
setwd("c:/Rwork/Part-III")
data <- read.csv("descriptive.csv", header=TRUE)
head(data) # 데이터셋 확인
dim(data) # 차원보기
length(data) # 열 길이
length(data$survey) # 컬럼 관찰치
str(data) # 데이터 구조보기
summary(data) # 요약통계량
length(data$gender) # 명목척도
summary(data$gender) # 명목척도 의미없음
table(data$gender) # 성별 빈도수 - outlier 확인(0, 5)
data <- subset(data,data$gender==1 | data$gender==2) # 성별 outlier제거
x <- table(data$gender) # 빈도수 저장
x
barplot(x) # 범주형 시각화 -> 막대차트
prop.table(x) # 빈도수 비율 계산
y <-  prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
length(data$level) # 학력수준 - 서열
summary(data$level) # 명목척도와 함께 의미없음
table(data$level)  # 빈도분석 - 의미있음
x1 <- table(data$level) # 각 학력수준에 빈도수 저장
x1
barplot(x1) # 명목/서열척도 -> 막대차트
survey <- data$survey
survey
summary(survey) # 만족도(5점 척도) -> 2.605(평균)
x1<-table(survey) # 빈도수
x1
hist(survey) # 등간척도 시각화 -> 히스토그림
length(data$cost)
summary(data$cost) # 요약통계량 - 의미있음(mean)
mean(data$cost) # NA
data$cost
plot(data$cost)
data <- subset(data,data$cost >= 2 & data$cost <= 10) # 총점기준
data
x<- data$cost
x
mean(x) # 평균 : 5.354
median(x) # 중위수 :  5.4
sort(x) # 오름차순
var(x) # 분산
sd(x) # 표준편차는 분산의 양의 제곱근
min(x) # 최소값
max(x) # 최대값
range(x) # 범위(min ~ max)
table(data$cost) # cost 빈도수
hist(data$cost) #
data$cost2[data$cost >=1 & data$cost <=3] <-1
data$cost2[data$cost >=4 & data$cost <=6] <-2
data$cost2[data$cost >=7] <-3
hist(data$cost2)
attach(data) #data를 붙여라!
length(cost)
summary(cost) # 요약통계량 - 의미있음(mean)
mean(cost) # 가장 의미있음
min(cost)
max(cost)
range(cost) # min ~ max
sort(cost) # 오름차순
sort(cost, decreasing=T) # 내림차순
install.packages("moments")  # 왜도/첨도 사용을 위한 패키지 설치
library(moments)
library(moments)
cost <- data$cost
skewness(cost) # 0보다 작으면 왼쪽 꼬리, 크면 오른쪽 꼬리
kurtosis(cost) # 2.683438   # 정규분포 첨도는 3
hist(cost)
hist(cost, freq = F)
lines(density(cost), col='blue')
x <- seq(0, 8, 0.1)
curve(dnorm(x, mean(cost), sd(cost)), col='red', add = T)
qqnorm(cost, main = 'cost : Q-Q plot')
qqline(cost, col='red')
shapiro.test(cost)
h <- rnorm(1000, mean=172.5, sd=2)
h
hist(h)
shapiro.test(h) # p-value = 0.1276 유의수준 > 0.05
install.packages("Hmisc") # 패키지 설치
library(Hmisc) # 메모리 로딩
describe(data) # Hmisc 패키지에서 제공되는 함수
describe(data$gender) # 명목척도
describe(data$age) # 비율척도
install.packages("prettyR")
library(prettyR)
freq(data) # 각 변수별 : 빈도수, 결측치(NA), 백분율
data$resident2[data$resident == 1] <-"특별시"
data$resident2[data$resident >=2 & data$resident <=4] <-"광역시"
data$resident2[data$resident == 5] <-"시구군"
x<- table(data$resident2)
prop.table(x) # 비율 계산
y <-  prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
data$gender2[data$gender== 1] <-"남자"
data$gender2[data$gender== 2] <-"여자"
x<- table(data$gender2)
prop.table(x) # 비율 계산
y <-  prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
summary(data$age)# 40 ~ 69
data$age2[data$age <= 45] <-"중년층"
data$age2[data$age >=46 & data$age <=59] <-"장년층"
data$age2[data$age >= 60] <-"노년층"
x<- table(data$age2)
x
prop.table(x) # 비율 계산
y <-  prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
data$level2[data$level== 1] <-"고졸"
data$level2[data$level== 2] <-"대졸"
data$level2[data$level== 3] <-"대학원졸"
x<- table(data$level2)
prop.table(x) # 비율 계산
y <-  prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
data$pass2[data$pass== 1] <-"합격"
data$pass2[data$pass== 2] <-"실패"
y<- table(data$pass2)
y
prop.table(x) # 비율 계산
y <-  prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
head(data)
describe(data)
summary(data$cost)
sum(data$cost)
describe(data)
summary(data$survey)
sum(data$survey, na.rm=T)
setwd("c:/Rwork/Part-III")
setwd("c:/Rwork/Part-III")
data <- read.csv("cleanDescriptive.csv", header=TRUE)
data # 확인
head(data) # 변수 확인
x <- data$level2 # 리코딩 변수 이용
y <- data$pass2 # 리코딩 변수 이용
x; y # 부모학력수준(x), 자녀대학진학여부(y)
result <- data.frame(Level=x, Pass=y) # 데이터 프레임 생성 - 데이터 묶음
dim(result) # 차원보기
table(result) # 빈도보기
install.packages("gmodels") # gmodels 패키지 설치
library(gmodels) # CrossTable() 함수 사용
install.packages("ggplot2") # diamonds 데이터 셋 사용을 위한 패키지 설치
install.packages("ggplot2")
library(ggplot2)
CrossTable(x=diamonds$color, y=diamonds$cut)
CrossTable(x=data$level2, y=data$pass2)
setwd("c:/Rwork/Part-III")
data <- read.csv("homogenity.csv", header=TRUE)
head(data)
data <- subset(data, !is.na(survey), c(method, survey))
head(data)
data$method2[data$method==1] <- "방법1"
data$method2[data$method==2] <- "방법2"
data$method2[data$method==3] <- "방법3"
data$survey2[data$survey==1] <- "매우만족"
data$survey2[data$survey==2] <- "만족"
data$survey2[data$survey==3] <- "보통"
data$survey2[data$survey==4] <- "불만족"
data$survey2[data$survey==5] <- "매우불만족"
table(data$method2, data$survey2)  # 교차표 생성 -> table(행,열)
