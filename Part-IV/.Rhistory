# maps 패키지에서 제공되는 map()함수
# map database을 이용하여 특별한 선이나 다각형을 그려준다.
# database와 투사방법에 의해서 지도가 그려진다.
# 형식) map(database, plot, fill, projection)
map = map("county", plot = F, fill = T, projection = "mercator")
# 형식)  mapplot(y축 ~ x축 , data, map)
mapplot(rownames(USCancerRates) ~ log(rate.male) + log(rate.female),
data = USCancerRates, map)
library(maps) #  map()함수
library(mapproj) # projection 지원
map = map("county", plot = F, fill = T, projection = "mercator")
mapplot(rownames(USCancerRates) ~ log(rate.male) + log(rate.female),
data = USCancerRates, map)
library(latticeExtra)
mapplot(rownames(USCancerRates) ~ log(rate.male) + log(rate.female),
data = USCancerRates, map)
library(DBI)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_60')
library(rJava)
library(RJDBC) # rJava에 의존적이다.(rJava 먼저 로딩)
install.packages(c("KoNLP", "tm", "wordcloud"))
#[실습]-------------------------------------------
myNoun <- extractNoun("내 이름은 홍길동 입니다.")
myNoun
paste(myNoun, collapse = " ") # 공백으로 단어 연결
library(KoNLP) # 한글처리 - Sejong(),extractNoun() 함수 제공
library(tm)  # 텍스트 마이닝 - Corpus()함수 제공
library(wordcloud) # 단어 구름 - RColorBrewer()함수 제공
#[실습]-------------------------------------------
myNoun <- extractNoun("내 이름은 홍길동 입니다.")
myNoun
paste(myNoun, collapse = " ") # 공백으로 단어 연결
data = read.csv("C:/Rwork/Part-II/abstract.txt",
header=TRUE, stringsAsFactors=FALSE)
# stringsAsFactors=FALSE : string을 범주로 사용하지 않음
head(data,1)# 1행 보기
str(data) # data.frame : 300 obs. of  4 variables:
result.txt <- Corpus(VectorSource(data[1:100,4]))
# 4번째 컬럼(abstract)만 100개 추출하여 corpus(자료집) 생성
result.txt # Content:  documents: 100
inspect(result.txt) #자료집 내용 보기- Content:  chars: 546
# 3) 분석 대상 자료집을 대상으로 NA 처리(공백)
result.txt[is.na(result.txt)]   <- ""
result.txt
# 4) 세종 사전 사용 및 단어 추가
useSejongDic() # 세종 사전 불러오기-KoNLP 제공
#Backup was just finished!
#87007 words were added to dic_user.txt
# 세종 사전에 없는 단어 추가
mergeUserDic(data.frame(c("소셜기업","클라우드펀딩","글로벌경제"), c("ncn")))
# ncn -명사지시코드
# 5) 단어추출 사용자 정의 함수
#  실행 순서 : 문자변환 -> 명사 단어추출 -> 공백으로 합침
exNouns <- function(x) {
paste(extractNoun(as.character(x)), collapse=" ")
}
#[실습]-------exNouns 함수 테스트 -------
text <- "나는 대한민국 사람 입니다."
exNouns(text) # [1] "나 대한 민국 사람"
#----------------------------------------
# (1) exNouns 함수 이용 단어 추출
# 형식) sapply(적용 데이터, 적용함수) : list 처리 함수
result_nouns <- sapply(result.txt, exNouns) # result.txt : list type
result_nouns[1] # 1번째 백터 요소 보기
# 6) 데이터 전처리
# 추출 단어 대상으로 자료집 다시 생성(why : 추출과정에 type 변경됨)
myCorpus <- Corpus(VectorSource(result_nouns))
myCorpus
myCorpus <- tm_map(myCorpus, removePunctuation) # 문장부호 제거
myCorpus <- tm_map(myCorpus, removeNumbers) # 수치 제거
myCorpus <- tm_map(myCorpus, tolower) # 소문자 변경
myCorpus <-tm_map(myCorpus, removeWords, stopwords('english')) # 불용어제거
# Stopwords 대상 : for, very, and, of, are 등
inspect(myCorpus[1:5]) # 데이터 전처리 결과 확인
myText <-tm_map(myCorpus, PlainTextDocument)
myText
myTerm <- TermDocumentMatrix(myText, control=list(wordLengths=c(2,Inf)))
myTerm # <<TermDocumentMatrix (terms: 4850, documents: 100)>>
# myTerm : 완전한 matrix형이 아님
myTerm.df <- as.data.frame(as.matrix(myTerm))
dim(myTerm.df) # [1] 4850  100
# 8) 단어 빈도수 구하기
wordResult <- sort(rowSums(myTerm.df), decreasing=TRUE) # 빈도수로 내림차순 정렬
wordResult[1:5] # 1~ 5번째 빈도수
#경영 전략 투자 자금 효과
#327  263  154  150  121
# 9) wordcloud 생성 (디자인 적용전)
myName <- names(wordResult) # 단어 이름 생성 -> 빈도수의 이름
wordcloud(myName, wordResult) # 단어구름 적성
x11( ) # 별도의 창을 띄우는 함수
word.df <- data.frame(word=myName, freq=wordResult)
str(word.df) # word, freq 변수
# 색상 지정(2개 중 하나 - 워드 색상 지정)
#pal <- brewer.pal(9,"Set1") # Set1~ Set3
pal <- brewer.pal(12,"Paired")
# 폰트 설정세팅 : "맑은 고딕", "서울남산체 B"
windowsFonts(malgun=windowsFont("맑은 고딕"))  #windows
# 색상, 빈도수, 글꼴, 회전 등 적용
wordcloud(word.df$word, word.df$freq,
scale=c(5,1), min.freq=3, random.order=F,
rot.per=.1, colors=pal, family="malgun")
# 11) 차트 시각화
topWord <- head(sort(wordResult, decreasing=T), 10) # 상위 10개 토픽추출
pie(topWord, col=rainbow(10), radius=1) # 파이 차트-무지개색, 원크기
pct <- round(topWord/sum(topWord)*100, 1) # 백분율
names(topWord)
# 키워드와 백분율 적용
lab <- paste(names(topWord), "\n", pct, "%")
pie(topWord, main="기업경영 논문집  토픽분석",
col=rainbow(10), cex=0.8, labels=lab)
par(new=T)
pie(topWord, radius=0.6, col="white", labels=NA, border=NA)
setwd("C:/Rwork/Part-IV")
mysales <- read.csv("Sales.csv", header = TRUE)
mysales
spectrum(mysales, col='red')
spectrum(mysales$Food, col='red')
plot.ts(mysales)
setwd("C:/Rwork/Part-IV")
mysales <- read.csv("Sales.csv", header = TRUE)
mysales
plot.ts(mysales)
spectrum(mysales, col='red')
spectrum(mysales$Food, col='red')
plot.ts(mysales$Food)
plot.ts(mysales$Food)
mysales
max(mysales$Food)
plot.ts(mysales$Food, col='red') # 2012~2013 사이 최고 빈도수
plot.ts(mysales$Food, col='blue') # 2012~2013 사이 최고 빈도수
spectrum(mysales$Food, col='red')
tsFood <- ts(mysales$Food, start=c(2011, 1), frequency=12)
tsFood # 2011 ~ 2014.05
# (3) 시계열모형 추정
tsFood2 <- auto.arima(tsFood) # 시계열모형 추정
tsFood2
library(forecast)
tsFood <- ts(mysales$Food, start=c(2011, 1), frequency=12)
tsFood # 2011 ~ 2014.05
# (3) 시계열모형 추정
tsFood2 <- auto.arima(tsFood) # 시계열모형 추정
tsFood2
# (4) 시계열모형으로 미래예측-forecast : 예측하다.
# - 기본 예측개월(2년)
plot(forecast(tsFood2)) # 2014.06~2016.05 예측 도식화
spectrum(mysales$Food, col='red')
tsFood3 <- forecast(tsFood2, level=c(80, 95), h=7)
tsFood3 # 7개월 데이터 예측
install.packages("XLConnect")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_60')
library(XLConnect)# readWorksheet() 제공
# excel data 가져오기
setwd("C:/Rwork/Part-IV")
series <- loadWorkbook("timeseries.xlsx", create=TRUE)
series
BizUnit <- readWorksheet(series, sheet="BizUnit")
BizUnit
setwd("C:/Rwork/Part-IV")
series <- loadWorkbook("timeseries.xlsx", create=TRUE)
series
BizUnit <- readWorksheet(series, sheet="BizUnit")
BizUnit
# (1) 일반 시계열 차트
attach(BizUnit)
plot(Quarter, BU_A, type="o", pch=18, col="blue", ylim=c(0, 2500), axes=F, ann=F)
axis(1, at=1:4, lab=c("1분기", "2분기", "3분기", "4분기"))
axis(2, ylim=c(0, 2500))
text(3.7, 2300, "사업부A", cex=0.8)
title(main="사업부 2015년 분기별 매출추이 비교", col.main="red", font.main=4)
title(xlab="분기", col.lab="blue")
title(ylab="매출액", col.lab="blue")
par(new=T) # 차트 추가
plot(Quarter, BU_B, type="o", pch=15, col="red", ylim=c(0, 2500), axes=F, ann=F)
text(3.7, 1600, "사업부B", cex=0.8)
par(new=T)
plot(Quarter, BU_C, type="o", pch=17, col="green", ylim=c(0, 2500), axes=F, ann=F)
text(3.7, 1100, "사업부C", cex=0.8)
par(new=T)
plot(Quarter, BU_D, type="o", pch=21, col="purple", ylim=c(0, 2500), axes=F, ann=F)
text(3.7, 700, "사업부D", cex=0.8)
par(new=T)
plot(Quarter, BU_E, type="o", pch=25, col="orange", ylim=c(0, 2500), axes=F, ann=F)
text(3.7, 100, "사업부E", cex=0.8)
detach(BizUnit)
series <- loadWorkbook("timeseries.xlsx", create=TRUE)
series
BizUnit2 <- readWorksheet(series, sheet="BizUnit2")
BizUnit2
attach(BizUnit2)
# ylim=c(0, 2500) -> ylim=c(0, 5), text(수정)
plot(Quarter, BU_A, type="o", pch=18, col="blue", ylim=c(0, 5), axes=F, ann=F)
axis(1, at=1:4, lab=c("1분기", "2분기", "3분기", "4분기"))
axis(2, ylim=c(0, 5))
text(3.7, 1.5, "사업부A", cex=0.8) # 텍스트 위치변경
title(main="사업부 2015년 분기별 성장률 추기 비교", col.main="red", font.main=4)
title(xlab="분기", col.lab="blue")
title(ylab="매출액", col.lab="blue")
par(new=T) # 차트 추가
plot(Quarter, BU_B, type="o", pch=15, col="red", ylim=c(0, 5), axes=F, ann=F)
text(3.7, 2.0, "사업부B", cex=0.8)
par(new=T)
plot(Quarter, BU_C, type="o", pch=17, col="green", ylim=c(0, 5), axes=F, ann=F)
text(3.7, 2.5, "사업부C", cex=0.8)
par(new=T)
plot(Quarter, BU_D, type="o", pch=21, col="purple", ylim=c(0, 5), axes=F, ann=F)
text(3.7, 3.0, "사업부D", cex=0.8)
par(new=T)
plot(Quarter, BU_E, type="o", pch=25, col="orange", ylim=c(0, 5), axes=F, ann=F)
text(3.7, 3.7, "사업부E", cex=0.8)
detach(BizUnit2)
library(ggplot2)
library(XLConnect) # readWorksheet() 제공
# excel data 가져오기
setwd("C:/Rwork/Part-IV")
series <- loadWorkbook("timeseries.xlsx", create=TRUE)
series
# Sales 워크시트 data 가져오기(행과 열 범위 지정)
Case2 <- readWorksheet(series, sheet="Case2", startRow=3, startCol=1, endRow=16, endCol=9)
Case2
# qplot(x, y, data)
qplot(Month, Sales, data=Case2) + geom_point()
qplot(Month, Sales, data=Case2, color="orange", geom="line") # 연결선 표시
#-----------------------------------------------
# ggplot(data, aes(x=변수,y=변수):꾸민다) + (geom_point():점스타일)
ggplot(Case2, aes(x=Month, y=Sales)) + geom_point() # qplot() 동일
ggplot(Case2, aes(x=Month, y=Sales)) + geom_line(color="orange") # qplot() 동일
#-----------------------------------------------
# smooth : 데이터의 추세선과 표준오차를 그래프로 나타낸다.
# (1) smooth 옵션
# qplot(x, y, data, geom, method)
qplot(Petal.Length, Petal.Width, data=iris,
geom=c("point", "smooth"), method="auto") # method 생략 가능
qplot(Petal.Length, Petal.Width, data=iris,
geom=c("point", "smooth"), method="lm") # 선형모델
# (2) 꽃의 종류로 색상 구분
# qplot(x, y, data, geom, method, colour)
qplot(Petal.Length, Petal.Width, data=iris,
geom=c("point", "smooth"),
method="auto", colour=Species)
qplot(Petal.Length, Petal.Width, data=iris,
geom=c("point", "smooth"),
method="lm", colour=Species)
qplot(Month, Sales, data=Case2) + geom_point()
qplot(Month, Sales, data=Case2, color="orange", geom="line") # 연결선 표시
#-----------------------------------
ggplot(Case2, aes(x=Month, y=Sales)) + geom_point() # qplot() 동일
ggplot(Case2, aes(x=Month, y=Sales)) + geom_line(color="orange") # qplot() 동일
#-
qplot(Petal.Length, Petal.Width, data=iris,
geom=c("point", "smooth"), method="auto") # method
qplot(Petal.Length, Petal.Width, data=iris,
geom=c("point", "smooth"), method="lm") # 선형모델
qplot(Petal.Length, Petal.Width, data=iris,
geom=c("point", "smooth"),
method="auto", colour=Species)
qplot(Petal.Length, Petal.Width, data=iris,
geom=c("point", "smooth"),
method="lm", colour=Species)
case <- readWorksheet(series, sheet="Case2", startRow=3, startCol=1,
endRow=16, endCol=9)
case
# Month기준 -> Sales(출하실적), Cpd1(0.2),Cpd2(0.4),Cpd3(0.6) 추세그래프
# 지수평활계수가 작을 수록 변동 폭 적음
ggplot(case, aes(x=Month, y=Sales)) +
geom_line(color="blue") +
geom_point(shape=15, color="blue", size=4) +
geom_line(aes(x=Month, y=Cpd1), color="red") +
geom_point(aes(x=Month, y=Cpd1), shape=16, color="red", size=4) +
geom_line(aes(x=Month, y=Cpd2), color="green") +
geom_point(aes(x=Month, y=Cpd2), shape=17, color="green", size=4) +
geom_line(aes(x=Month, y=Cpd3), color="purple") +
geom_point(aes(x=Month, y=Cpd3), shape=18, color="purple", size=4)
library(forecast)
input <- c(5200,5100,5400,5300,5500,5400,5600,5900,5400,5600,5400,5800)
input # 확인
# (1) 시계열 데이터 생성 - ts() : states 패키지 제공
tsscore <- ts(input, start=c(2011, 1), frequency=12) # Time Series
# 시작은 2011년 1월 ~ 12개월 주기
tsscore # forecast에서 다음과 같은 데이터를 원함
# (2) 시계열 모형 추정
tsscore2 <- auto.arima(tsscore) # 시계열 데이터 이용
tsscore2
# (3) 시계열모형 추정으로 미래값 예측
#-------------------------------
# - 기본 예측개월(24개월 - 2년) - level=c(80,95)
tsscore3 <- forecast(tsscore2) # 미래값 예측-시계열모형 예측
tsscore3
plot(tsscore3) # 미래값 예측 도식화
# - 6개월 예측(0.5년)
tsscore3 <- forecast(tsscore2, h=6) # 향후 3개월 예측
tsscore3
plot(tsscore3)
# 2. 시계열 데이터 파일로 미래 예측
# 데이터 파일 가져오기
setwd("C:/Rwork/Part-IV")
mysales <- read.csv("Sales.csv", header = TRUE)
mysales
# (1) 시계열 데이터 빈도분석 시각화
max(mysales$Food) # 2750
plot.ts(mysales$Food, col='blue') # 2012~2013 사이 최고 빈도수
spectrum(mysales$Food, col='red') # 10년 주기에서 강한 주기
# y축:로그척도(데시벨), x축:대역폭(10년), 파랑선 : 데시벨 95% 신뢰구간
# (2) 시계열 데이터 생성
tsFood <- ts(mysales$Food, start=c(2011, 1), frequency=12)
tsFood # 2011 ~ 2014.05
# (3) 시계열모형 추정
tsFood2 <- auto.arima(tsFood) # 시계열모형 추정
tsFood2
# 1) matrix 생성
x <- matrix(1:16, nrow=4)
x
dist <- dist(x, method="euclidean")
# 형식) dist(x, method="euclidean") -> x : numeric matrix, data frame
dist
install.packages("cluster") # hclust() : 계층적 클러스터 함수 제공
library(cluster)
hc <- hclust(dist) # 클러스터링 적용
plot(hc) # 클러스터 플로팅
#<실습> 중1학년 신체검사 결과 군집분석
body <- read.csv("c:/Rwork/Part-Iv/bodycheck.csv", header=TRUE)
body[,-1]
body
idist<- dist(body[, -1]) # dist(iris[, -5])
head(idist)
idist
hc <- hclust(idist)
hc
plot(hc, hang=-1) # 음수값 제외
#<실습> iris 데이터셋 군집분석
#-------------------------------------
data(iris)
iris[1:5,]  # 1~5행
iris[1:5,-5] # 숫자 컬럼만 선택
iris
# 거리구하기-iris 데이터셋으로 유클리드 거리 계산
dist(iris[1:5, -5]) # 5컬럼 제외
# 유클리드 거리 matrix를 이용한 클러스터링
dist<- dist(iris[1:5, -5])
hc <- hclust(dist)
plot(hc)
iris[1:5,]  # 1~5행
iris[1:5,-5] # 숫자 컬럼만 선택
iris
# 거리구하기-iris 데이터셋으로 유클리드 거리 계산
dist(iris[1:5, -5]) # 5컬럼 제외
# 유클리드 거리 matrix를 이용한 클러스터링
dist<- dist(iris[1:5, -5])
hc <- hclust(dist)
plot(hc)
dist<- dist(iris[1:5, -5])
hc <- hclust(dist)
plot(hc)
result <- read.csv("C:/Rwork/data/drinking_water.csv", header=TRUE)
head(result)
# 상관계수 보기
cor(result$친밀도, result$적절성)
cor(result$친밀도, result$만족도)
cor(result, method="pearson") # 피어슨 상관계수 - default
cor(result, method="spearman") # spearman 상관계수(서열척도)
result <- read.csv("C:/Rwork/data/drinking_water.csv", header=TRUE)
head(result) # 친밀도 적절성 만족도(등간척도 - 5점 척도)
# 상관계수 보기 - 높은 상관관계를 나타냄
help(cor)
# 형식) cor(x,y, method) # x변수, y변수, method(pearson): 방법
cor(result$친밀도, result$적절성) # 0.4992086 -> 다소 높은 양의 상관관계
# ±0.9 ~ ±0.7: 관련성 높음, 적어도 ±6이상, 논문(±0.4)이상
cor(result$친밀도, result$만족도) # 0.467145 -> 다소 높은 양의 상관관계
# [실습] 적절성과 만족도 상관계수 보기
cor(result$적절성, result$만족도) # 0.7668527 -> 높은 양의 상관관계
# [실습] 적절성+친밀도 -> 만족도 상관계수 보기
cor(result$적절성+result$친밀도, result$만족도)
# 전체 변수 간 상관계수 보기
# 형식) cor(dataset, method)
# pearson : 두 변수간의 관련성을 구하기 위해 보편적으로 이용된다.
cor(result, method="pearson") # 피어슨 상관계수 - default
#         친밀도    적절성    만족도
#친밀도 1.0000000 0.4992086 0.4671450
#적절성 0.4992086 1.0000000 0.7668527
#만족도 0.4671450 0.7668527 1.0000000
# 대각선은 자기 상관계수
# 방향성 있는 색생으로 표현 - 동일 색상으로 그룹화 표시 및 색의 농도
library(corrgram)
corrgram(result) # 색상 적용 - 동일 색상으로 그룹화 표시
corrgram(result, upper.panel=panel.conf) # 수치(상관계수) 추가(위쪽)
corrgram(result, lower.panel=panel.conf) # 수치(상관계수) 추가(아래쪽)
# 해석 : total 가장 큰 영향을 미치는 변수는 price > period 순, variety 영향 없음
# 차트에 곡선과 별표 추가
library(PerformanceAnalytics)
# 상관성,p값(*),정규분포 시각화
chart.Correlation(result, histogram=, pch="+")
# spearman : 서열척도 대상 상관계수
cor(result, method="spearman")
sd(result$친밀도);sd(result$적절성);sd(result$만족도)
cor(result, method="spearman")
sd(result$친밀도);sd(result$적절성);sd(result$만족도)
summary(result)
sd(result$친밀도);sd(result$적절성);sd(result$만족도)
result <- read.csv("C:/Rwork/data/drinking_water.csv", header=TRUE)
head(result) # 친밀도 적절성 만족도(등간척도 - 5점 척도)
summary(result) # 요약통계량
# 표준편차 - 0에 가까울 수록 관측값이 동일함
sd(result$친밀도);sd(result$적절성);sd(result$만족도)
str(result) # 'data.frame':  264 obs. of  3 variables:
y = result$만족도 # 종속변수
x = result$적절성 # 독립변수
result.lm <- lm(formula=y ~ x, data=result)
# 선형회귀 분석 결과 보기
summary(result.lm)
library(PerformanceAnalytics)
chart.Correlation(result, histogram=, pch="+")
plot(formula=y ~ x, data=result)
abline(result.lm)
result.lm <- lm(formula=Sepal.Length ~ Sepal.Width+Petal.Length, data=train)
result.lm <- lm(formula=Sepal.Length ~ Sepal.Width+Petal.Length, data=test)
result.lm
summary(result.lm)
result2 <- predict(result.lm, test)# x변수만 test에서 찾아서 값 예측
result2
length(result2) # 45개 벡터
library(car)
fit()
fit()
library(car)
vif
vif
fit <- lm(formula=Sepal.Length ~ Sepal.Width+Petal.Length+Petal.Width, data=train)
vif(fit)
sqrt(vif(fit))
sqrt(vif(fit))>2 # root(VIF)가 2 이상인 것은 다중공선성 문제 의심
cor(iris[,-5]) # 변수간의 상관계수 보기(Species 제외)
result.lm <- lm(formula=Sepal.Length ~ Sepal.Width+Petal.Length, data=train)
result.lm <- lm(formula=Sepal.Length ~ Sepal.Width+Petal.Length, data=test)
result.lm
summary(result.lm)
result2 <- predict(result.lm, test)# x변수만 test에서 찾아서 값 예측
result2
length(result2) # 45개 벡터
x <- sample(1:nrow(iris), 0.7*nrow(iris)) # 전체중 70%만 추출
train <- iris[x, ] # 학습데이터 추출
test <- iris[-x, ] # 검정데이터 추출
# (4) Petal.Width 변수를 제거한 후 회귀분석
result.lm <- lm(formula=Sepal.Length ~ Sepal.Width+Petal.Length, data=train)
result.lm <- lm(formula=Sepal.Length ~ Sepal.Width+Petal.Length, data=test)
result.lm
summary(result.lm)
result2 <- predict(result.lm, test)# x변수만 test에서 찾아서 값 예측
result2
length(result2) # 45개 벡터
head(test) # x,y값 확인
library(party)
data(iris)
summary(iris)
#단계1 : 학습데이터와 검증데이터 샘플링
result <- sample(2, nrow(iris),replace=T, prob=c(0.7,0.3))
table(result) # 7:3비율 데이터 생성
train <- iris[result==1,]
test <- iris[result==2,]
# formula 생성 -> 형식) 변수 <- 종속변수 ~ 독립변수
formula <- Species ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width
#단계2 : ctree() 이용 - 분류모델 생성
iris_ctree <- ctree(formula, data=train) # 학습데이터로 분류모델(tree) 생성
iris_ctree # Petal.Length,Petal.Width 중요변수
table(predict(iris_ctree), train$Species)
#단계4 : 분류모델 플로팅
# plot() 이용 - 의사결정 트리로 결과 플로팅
plot(iris_ctree, type="simple")
plot(iris_ctree)
# <실습> 검증데이터를 이용하여 분류모델을 생성하고 테이블 형식과
#       의사결정트리를 플로팅하시오.
# 1) 분류모델 생성
iris_ctree2 <- ctree(formula, data=test)
# 2) 분류예측 결과를 테이블로 제시
testpred <- predict(iris_ctree2, test) # 검증데이터 적용
table(testpred,test$Species) # ②
# 3) 의사결정 트리 플로팅
plot(iris_ctree2)
table(testpred,test$Species) # 빈도분
# 3) 의사결정 트리 플로팅
plot(iris_ctree2)
weather = read.csv(file.choose(), header=TRUE)
str(weather) # data.frame':  366 obs. of  24 variables:
str(weather) # data.frame':  366 obs. of  24 variables:
names(weather) # 24개 변수명
head(weather)
library(rpart)
weather.df <- rpart(RainTomorrow~., data=weather[, c(-1,-2,-23,-22)])
weather.df
# 3) 분류 트리 생성
plot(weather.df) # 트리 프레임 보임
text(weather.df, use.n=T) # 텍스트 추가
post(weather.df, file="") # 타원제공 - rpart 패키지 제공
# <실습2> weather(전체 데이터)를 7:3으로 나누어 weather_train, weather_test로
# 저장한 후 weather_train으로 분류모델을 생성하고, weather_test로 예측하시오.
# 예측 결과가 50%를 기준으로 이상이면 비가오는 것으로(Rain), 작으면 비가
# 안오는(No Rain)것으로 해서 테이블을 작성하시오.
# (1) 데이터 셈플링
index = sample(1:nrow(weather), 0.7*nrow(weather))
weather_train = weather[index,]
weather_test = weather[-index,]
# (2) 분류모델 생성
weather.dt <- rpart(RainTomorrow~., data=weather_train[,c(-1,-2,-23,-22)])
weather.dt
# (3) 분류모델 예측 - 검정데이터로 예측
predict(weather.dt, weather_test[1:10,])
weather.predicted = predict(weather.dt, weather_test) # 예측
weather.predicted
result = ifelse(weather.predicted[,2]>0.5, "Rain", "No") # [,2] : Yes
#result = ifelse(as.numeric(weather.predicted[,2])>0.5, "Rain", "No")
# (4) 분류모델 예측 결과
table(weather_test$RainTomorrow, result)
testpred <- predict(iris_ctree2, test) # 검증데이터 적용
table(testpred,test$Species) # 빈도분
